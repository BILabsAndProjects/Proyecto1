{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21545bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys, site, platform, os, subprocess,time, json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ac84d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY cargada correctamente: True\n"
     ]
    }
   ],
   "source": [
    "# cargar dotenv (instala python-dotenv si hace falta)\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()   # carga .env desde el working dir o sus padres\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "secret = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not secret:\n",
    "    raise RuntimeError(\n",
    "        \"OPENAI_API_KEY no encontrada. Verifica .env en la ruta y que tenga formato: OPENAI_API_KEY=sk-... (sin comillas)\"\n",
    "    )\n",
    "\n",
    "# No imprimir la clave. Verificar solo que se carg√≥:\n",
    "print(\"OPENAI_API_KEY cargada correctamente:\", bool(secret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2fba1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python exe: c:\\Users\\aleja\\anaconda3\\envs\\bi\\python.exe\n",
      "Version: 3.12.9 | packaged by conda-forge | (main, Mar  4 2025, 22:37:18) [MSC v.1943 64 bit (AMD64)]\n",
      "Site-packages: ['c:\\\\Users\\\\aleja\\\\anaconda3\\\\envs\\\\bi', 'c:\\\\Users\\\\aleja\\\\anaconda3\\\\envs\\\\bi\\\\Lib\\\\site-packages']\n",
      "OS: Windows-11-10.0.26100-SP0\n"
     ]
    }
   ],
   "source": [
    "print(\"Python exe:\", sys.executable)\n",
    "print(\"Version:\", sys.version)\n",
    "print(\"Site-packages:\", site.getsitepackages() if hasattr(site,\"getsitepackages\") else site.getusersitepackages())\n",
    "print(\"OS:\", platform.platform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9611228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK SDK v1.x, modelos: 96\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=secret)\n",
    "models = client.models.list()\n",
    "print(\"OK SDK v1.x, modelos:\", len(models.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad202a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ODS encontrados: [1, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "TEXTO = \"textos\"  # columna de la opini√≥n\n",
    "ODS = \"labels\"  # columna de etiqueta 1,3,4\n",
    "\n",
    "df = pd.read_excel(r\"datos/Datos_proyecto.xlsx\")\n",
    "ods_list = sorted(df[ODS].unique())\n",
    "print(\"ODS encontrados:\", ods_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123b8d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generando dataset sint√©tico #1 ---\n",
      "ODS 1: 32 nuevos ejemplos\n",
      "Tokens usados: prompt=1205, completion=1382, total=2587\n",
      "ODS 3: 32 nuevos ejemplos\n",
      "Tokens usados: prompt=1455, completion=1122, total=2577\n",
      "ODS 4: 31 nuevos ejemplos\n",
      "Tokens usados: prompt=1218, completion=1152, total=2370\n",
      "Dataset sint√©tico 1 ‚Üí 95 filas\n",
      "\n",
      "--- Generando dataset sint√©tico #2 ---\n",
      "ODS 1: 31 nuevos ejemplos\n",
      "Tokens usados: prompt=1205, completion=1306, total=2511\n",
      "ODS 3: 32 nuevos ejemplos\n",
      "Tokens usados: prompt=1455, completion=1216, total=2671\n",
      "ODS 4: 28 nuevos ejemplos\n",
      "Tokens usados: prompt=1218, completion=1168, total=2386\n",
      "Dataset sint√©tico 2 ‚Üí 91 filas\n",
      "\n",
      "--- Generando dataset sint√©tico #3 ---\n",
      "ODS 1: 30 nuevos ejemplos\n",
      "Tokens usados: prompt=1205, completion=1346, total=2551\n",
      "ODS 3: 30 nuevos ejemplos\n",
      "Tokens usados: prompt=1455, completion=1109, total=2564\n",
      "ODS 4: 31 nuevos ejemplos\n",
      "Tokens usados: prompt=1218, completion=1272, total=2490\n",
      "Dataset sint√©tico 3 ‚Üí 91 filas\n",
      "\n",
      "--- Generando dataset sint√©tico #4 ---\n",
      "ODS 1: 30 nuevos ejemplos\n",
      "Tokens usados: prompt=1205, completion=1204, total=2409\n",
      "ODS 3: 31 nuevos ejemplos\n",
      "Tokens usados: prompt=1455, completion=1045, total=2500\n",
      "ODS 4: 32 nuevos ejemplos\n",
      "Tokens usados: prompt=1218, completion=1087, total=2305\n",
      "Dataset sint√©tico 4 ‚Üí 93 filas\n",
      "\n",
      "--- Generando dataset sint√©tico #5 ---\n",
      "ODS 1: 31 nuevos ejemplos\n",
      "Tokens usados: prompt=1205, completion=1238, total=2443\n",
      "ODS 3: 31 nuevos ejemplos\n",
      "Tokens usados: prompt=1455, completion=1134, total=2589\n",
      "ODS 4: 31 nuevos ejemplos\n",
      "Tokens usados: prompt=1218, completion=1059, total=2277\n",
      "Dataset sint√©tico 5 ‚Üí 93 filas\n"
     ]
    }
   ],
   "source": [
    "def generar_opiniones(ods_id, ejemplos_ref, n=30):\n",
    "    \"\"\"Genera n ejemplos sint√©ticos para un ODS espec√≠fico\"\"\"\n",
    "    ejemplos = \"\\n\".join(f\"- {s}\" for s in ejemplos_ref)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Genera {n} opiniones ciudadanas breves (1‚Äì2 oraciones), en espa√±ol de Colombia,\n",
    "    realistas y respetuosas, sobre problem√°ticas locales mapeadas SOLO al ODS {ods_id}.\n",
    "    Definici√≥n de cada ODS:\n",
    "    ODS 1: Fin de la pobreza, ODS 3: Salud y Bienestar, ODS 4: Educaci√≥n de calidad.\n",
    "\n",
    "    Requisitos:\n",
    "    - TODAS deben corresponder al ODS {ods_id}.\n",
    "    - Var√≠a zonas (urbano/rural), actores e instituciones; evita datos personales.\n",
    "    - Mant√©n neutralidad pol√≠tica y sin contenido sensible.\n",
    "    - Entrega SOLO JSON v√°lido: una lista de objetos con:\n",
    "      \"textos\" (string) y \"labels\" (entero {ods_id}).\n",
    "\n",
    "    Ejemplos reales del dataset (NO copiar literalmente):\n",
    "    {ejemplos if ejemplos_ref else '- (sin ejemplos de contexto)'}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Eres un generador de datos sint√©ticos.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    txt = response.choices[0].message.content.strip()\n",
    "    if txt.startswith(\"```\"):\n",
    "        txt = txt.strip(\"`\")\n",
    "        if \"\\n\" in txt:\n",
    "            txt = txt.split(\"\\n\", 1)[1]\n",
    "\n",
    "    data = json.loads(txt)\n",
    "    df_new = pd.DataFrame(data)\n",
    "    df_new[\"labels\"] = ods_id\n",
    "\n",
    "    print(f\"ODS {ods_id}: {len(df_new)} nuevos ejemplos\")\n",
    "    print(f\"Tokens usados: prompt={response.usage.prompt_tokens}, completion={response.usage.completion_tokens}, total={response.usage.total_tokens}\")\n",
    "    return df_new\n",
    "\n",
    "\n",
    "# Generar 5 datasets sint√©ticos diferentes\n",
    "datasets = []\n",
    "for i in range(1, 6):\n",
    "    print(f\"\\n--- Generando dataset sint√©tico #{i} ---\")\n",
    "\n",
    "    df_sintetico = pd.DataFrame(columns=[TEXTO, ODS])\n",
    "    for ods_id in ods_list:\n",
    "        # Muestras de referencia de ese ODS\n",
    "        ejemplos_ref = (\n",
    "            df[df[ODS] == ods_id][TEXTO]\n",
    "            .dropna()\n",
    "            .astype(str)\n",
    "            .sample(min(8, sum(df[ODS] == ods_id)), random_state=42)\n",
    "            .tolist()\n",
    "        )\n",
    "\n",
    "        nuevos = generar_opiniones(ods_id, ejemplos_ref, n=30)\n",
    "        df_sintetico = pd.concat([df_sintetico, nuevos], ignore_index=True)\n",
    "\n",
    "    df_sintetico = df_sintetico.sample(frac=1, random_state=i).reset_index(drop=True)\n",
    "    datasets.append(df_sintetico)\n",
    "    print(f\"Dataset sint√©tico {i} ‚Üí {len(df_sintetico)} filas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8d5f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df_syn in enumerate(datasets, start=1):\n",
    "    df_syn.to_excel(f\"datos_pruebas_sintenticos/Datos_sinteticos_{i}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f06932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generando archivo de prueba #1 ---\n",
      "73 textos generados.\n",
      "Tokens usados: prompt=1384, completion=3190, total=4574\n",
      "\n",
      "--- Generando archivo de prueba #2 ---\n",
      "63 textos generados.\n",
      "Tokens usados: prompt=1384, completion=2554, total=3938\n",
      "\n",
      "--- Generando archivo de prueba #3 ---\n",
      "76 textos generados.\n",
      "Tokens usados: prompt=1384, completion=3144, total=4528\n",
      "\n",
      "--- Generando archivo de prueba #4 ---\n",
      "66 textos generados.\n",
      "Tokens usados: prompt=1384, completion=2739, total=4123\n",
      "\n",
      "--- Generando archivo de prueba #5 ---\n",
      "85 textos generados.\n",
      "Tokens usados: prompt=1384, completion=2807, total=4191\n",
      "‚úÖ Archivos generados y guardados.\n"
     ]
    }
   ],
   "source": [
    "df_ref = pd.read_excel(r\"datos/Datos de prueba_proyecto.xlsx\")\n",
    "\n",
    "# Toma una muestra representativa para dar contexto al modelo\n",
    "ejemplos_ref = df_ref[\"Textos_espanol\"].sample(min(10, len(df_ref)), random_state=42).tolist()\n",
    "ejemplos = \"\\n\".join(f\"- {s}\" for s in ejemplos_ref)\n",
    "\n",
    "\n",
    "def generar_textos_similares(ejemplos_ref, n=100):\n",
    "    \"\"\"Genera n textos similares al archivo de referencia (sin etiquetas)\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Tienes ejemplos de opiniones ciudadanas reales en espa√±ol de Colombia.\n",
    "\n",
    "    Genera {n} nuevos textos que se parezcan en tono, extensi√≥n y estilo a estos ejemplos,\n",
    "    pero con contenido totalmente nuevo (no repetir ni copiar frases).\n",
    "    Las opiniones deben sonar naturales y variadas, sobre situaciones cotidianas\n",
    "    que podr√≠a mencionar una persona en su comunidad.\n",
    "\n",
    "    Ejemplos de referencia:\n",
    "    {ejemplos}\n",
    "\n",
    "    Entrega la respuesta en formato JSON v√°lido, con una lista de objetos:\n",
    "    [{{\"textos\": \"opini√≥n...\" }}, ...]\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Eres un generador de textos ciudadanos realistas.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.8,\n",
    "    )\n",
    "\n",
    "    txt = response.choices[0].message.content.strip()\n",
    "    if txt.startswith(\"```\"):\n",
    "        txt = txt.strip(\"`\")\n",
    "        if \"\\n\" in txt:\n",
    "            txt = txt.split(\"\\n\", 1)[1]\n",
    "\n",
    "    data = json.loads(txt)\n",
    "    df_new = pd.DataFrame(data)\n",
    "\n",
    "    print(f\"{len(df_new)} textos generados.\")\n",
    "    print(f\"Tokens usados: prompt={response.usage.prompt_tokens}, completion={response.usage.completion_tokens}, total={response.usage.total_tokens}\")\n",
    "    return df_new\n",
    "\n",
    "\n",
    "# üîÅ Crear varios archivos de prueba similares\n",
    "n_archivos = 5\n",
    "textos_por_archivo = 120\n",
    "datasets_no_label = []\n",
    "\n",
    "for i in range(1, n_archivos + 1):\n",
    "    print(f\"\\n--- Generando archivo de prueba #{i} ---\")\n",
    "    df_fake = generar_textos_similares(ejemplos_ref, n=textos_por_archivo)\n",
    "    datasets_no_label.append(df_fake)\n",
    "    df_fake.to_excel(f\"datos_pruebas_sintenticos/Textos_prueba_{i}.xlsx\", index=False)\n",
    "\n",
    "print(\"Archivos generados y guardados.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
