{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bfe3ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from langdetect import detect\n",
    "from scipy.stats import f_oneway\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "from nltk.stem.snowball import SpanishStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c04b2f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textos</th>\n",
       "      <th>labels</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Aprendizaje\" y \"educación\" se consideran sinó...</td>\n",
       "      <td>4</td>\n",
       "      <td>aprendizaje educación consideran sinónimos esc...</td>\n",
       "      <td>[aprendizaje, educación, consideran, sinónimos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Para los niños más pequeños (bebés y niños peq...</td>\n",
       "      <td>4</td>\n",
       "      <td>niños pequeños bebés niños pequeños capacitaci...</td>\n",
       "      <td>[niños, pequeños, bebés, niños, pequeños, capa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Además, la formación de especialistas en medic...</td>\n",
       "      <td>3</td>\n",
       "      <td>además formación especialistas medicina genera...</td>\n",
       "      <td>[además, formación, especialistas, medicina, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>En los países de la OCDE se tiende a pasar de ...</td>\n",
       "      <td>4</td>\n",
       "      <td>países ocde tiende pasar cursos obligatorios o...</td>\n",
       "      <td>[países, ocde, tiende, pasar, cursos, obligato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Este grupo se centró en las personas que padec...</td>\n",
       "      <td>3</td>\n",
       "      <td>grupo centró personas padecen trastornos menta...</td>\n",
       "      <td>[grupo, centró, personas, padecen, trastornos,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              textos  labels  \\\n",
       "0  \"Aprendizaje\" y \"educación\" se consideran sinó...       4   \n",
       "1  Para los niños más pequeños (bebés y niños peq...       4   \n",
       "2  Además, la formación de especialistas en medic...       3   \n",
       "3  En los países de la OCDE se tiende a pasar de ...       4   \n",
       "4  Este grupo se centró en las personas que padec...       3   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  aprendizaje educación consideran sinónimos esc...   \n",
       "1  niños pequeños bebés niños pequeños capacitaci...   \n",
       "2  además formación especialistas medicina genera...   \n",
       "3  países ocde tiende pasar cursos obligatorios o...   \n",
       "4  grupo centró personas padecen trastornos menta...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [aprendizaje, educación, consideran, sinónimos...  \n",
       "1  [niños, pequeños, bebés, niños, pequeños, capa...  \n",
       "2  [además, formación, especialistas, medicina, g...  \n",
       "3  [países, ocde, tiende, pasar, cursos, obligato...  \n",
       "4  [grupo, centró, personas, padecen, trastornos,...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_excel(r\"datos/Datos_proyecto.xlsx\")\n",
    "df_data.head()\n",
    "df = df_data.dropna(subset=[\"textos\", \"labels\"])\n",
    "df = df.drop_duplicates(subset=[\"textos\", \"labels\"])\n",
    "\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"spanish\"))\n",
    "\n",
    "spanish_stemmer = SpanishStemmer()\n",
    "\n",
    "\n",
    "def tokenize_text(text, stem=True):\n",
    "    # Elimina caracteres especiales y espacios en blanco\n",
    "    doc = re.sub(r\"[^A-Za-zÁÉÍÓÚáéíóúÜüÑñ\\s]\", \"\", text, flags=re.U)  # Unicode aware\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # Tokenizar documento\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # Filtrar palabras\n",
    "    filtered_tokens = [\n",
    "        spanish_stemmer.stem(token) if stem else token\n",
    "        for token in tokens\n",
    "        if token not in stop_words\n",
    "    ]\n",
    "    # Recrear documento de texto\n",
    "    doc = \" \".join(filtered_tokens)\n",
    "    return doc, filtered_tokens\n",
    "\n",
    "\n",
    "normalized_df = df.copy()\n",
    "normalized_df[[\"tokenized_text\", \"tokens\"]] = normalized_df[\"textos\"].apply(\n",
    "    lambda x: pd.Series(tokenize_text(x, stem=False))\n",
    ")\n",
    "\n",
    "\n",
    "normalized_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7c5e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalized_df[\"tokenized_text\"]\n",
    "y = normalized_df[\"labels\"]\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18cb70d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-grama (1, 1):\n",
      "F1 score: 0.9712130330842402\n",
      "Precision: 0.974286810311103\n",
      "Recall: 0.9686968049298327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.93      0.95        82\n",
      "           3       0.96      0.99      0.98       125\n",
      "           4       0.99      0.99      0.99       157\n",
      "\n",
      "    accuracy                           0.98       364\n",
      "   macro avg       0.97      0.97      0.97       364\n",
      "weighted avg       0.98      0.98      0.98       364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def logistic_n_gram(n_grama_param, X_train, X_test, y_train, y_test):\n",
    "    vectorizer_ngram = CountVectorizer(ngram_range=n_grama_param)\n",
    "    X_train_ngram = vectorizer_ngram.fit_transform(X_train.fillna(\"\"))\n",
    "    X_test_ngram = vectorizer_ngram.transform(X_test.fillna(\"\"))\n",
    "\n",
    "    # Modelo\n",
    "    log_n = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    log_n.fit(X_train_ngram, y_train)\n",
    "    y_pred = log_n.predict(X_test_ngram)\n",
    "\n",
    "    # Métricas\n",
    "    print(f\"N-grama {n_grama_param}:\")\n",
    "    print(\"F1 score:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred, average=\"macro\"))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred, average=\"macro\"))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "logistic_n_gram((1, 1), X_train_text, X_test_text, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a3589c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2214, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_excel(r\"datos/Datos_aumentados_train.xlsx\")\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d519cefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2214, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df22 = df2.drop_duplicates(subset=[\"textos\", \"labels\"])\n",
    "\n",
    "df22.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f196af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "from sklearn.pipeline import FunctionTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f819485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"datos/Datos_proyecto.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e1f6571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\laura\\AppData\\Local\\Temp\\ipykernel_4896\\3595354441.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nclass WordTokenizerTransformer:\\n    def __init__(self):\\n        pass\\n    \\n    def fit(self, X, y=None):\\n        # No necesita entrenamiento pero permite compatibilidad scikit-learn\\n        self.stem = False\\n        self.wpt = nltk.WordPunctTokenizer()\\n        self.stop_words = set(nltk.corpus.stopwords.words(\"spanish\"))\\n        self.spanish_stemmer = SpanishStemmer()\\n        return self\\n\\n    def transform(self, X):\\n\\n        df = X.copy()\\n        \\n        for index, row in df.iterrows():\\n            text = row[\\'textos\\']\\n            doc = re.sub(r\"[^A-Za-zÁÉÍÓÚáéíóúÜüÑñ\\\\s]\", \"\", text, flags=re.U)  # Unicode aware\\n            doc = doc.lower()\\n            doc = doc.strip()\\n            tokens = self.wpt.tokenize(doc)\\n            # Filtrar palabras\\n            filtered_tokens = [\\n                self.spanish_stemmer.stem(token) if self.stem else token\\n                for token in tokens\\n                if token not in self.stop_words\\n            ]\\n            # Recrear documento de texto\\n            doc = \" \".join(filtered_tokens)\\n            df.loc[index, \\'tokenized_text\\'] = doc\\n        return df\\n\\n    def fit_transform(self, X, y=None):\\n        return self.fit(X, y).transform(X)\\n\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class WordTokenizerTransformer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # No necesita entrenamiento pero permite compatibilidad scikit-learn\n",
    "        self.stem = False\n",
    "        self.wpt = nltk.WordPunctTokenizer()\n",
    "        self.stop_words = set(nltk.corpus.stopwords.words(\"spanish\"))\n",
    "        self.spanish_stemmer = SpanishStemmer()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        df = X.copy()\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            text = row['textos']\n",
    "            doc = re.sub(r\"[^A-Za-zÁÉÍÓÚáéíóúÜüÑñ\\s]\", \"\", text, flags=re.U)  # Unicode aware\n",
    "            doc = doc.lower()\n",
    "            doc = doc.strip()\n",
    "            tokens = self.wpt.tokenize(doc)\n",
    "            # Filtrar palabras\n",
    "            filtered_tokens = [\n",
    "                self.spanish_stemmer.stem(token) if self.stem else token\n",
    "                for token in tokens\n",
    "                if token not in self.stop_words\n",
    "            ]\n",
    "            # Recrear documento de texto\n",
    "            doc = \" \".join(filtered_tokens)\n",
    "            df.loc[index, 'tokenized_text'] = doc\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38315bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb0fc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 1490                                                                                                                                                            Por lo general, se entiende que los trastornos de leves a moderados no requieren tratamientos altamente especializados administrados por psiquiatras o en entornos hospitalarios en la gran mayoría de los casos. En cambio, en la mayoría de los países de la OCDE, los médicos de atención primaria asumen un papel de liderazgo en el tratamiento de trastornos leves a moderados (ver Tabla 4.2). Cuando la provisión a nivel de atención primaria para los trastornos leves a moderados está respaldada por una buena capacitación (tanto durante la capacitación médica como como parte de la educación médica continua), por el apoyo de profesionales especialistas en atención de la salud mental y redes de apoyo, y por buenas opciones de derivación si un paciente necesita acceder a un nivel de atención más especializado, puede ser una forma muy eficaz de brindar atención a un gran número de pacientes.\n",
       "387                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               En la mayoría de los contratos, el objetivo es llegar a cuatro o cinco pacientes por hora, cumpliendo también con los estándares de calidad especificados. En la encuesta nacional de salud de 2006, por ejemplo, el 31% de la población reportó obtener servicios de salud del sector privado al menos una vez al año, independientemente de su cobertura bajo la CCSS. En 2009, el 60% de los encuestados afirmó que prefería proveedores privados de atención médica (Gutiérrez, 2009).\n",
       "1419                                                                                                                                                                                                                                                                                                                                            Las tasas de consumo de alcohol y tabaquismo no han disminuido y se encuentran entre las más altas de la UE. Las tasas de obesidad, aunque siguen siendo más bajas que en muchos otros países de la UE, están aumentando tanto en adultos como en adolescentes. Alentadoramente, las tasas de tabaquismo entre los adolescentes disminuyeron en los últimos años y Austria finalmente se está poniendo al día con otros países de la UE en términos de políticas para la protección de los no fumadores, por ejemplo, mediante la introducción de una prohibición total de fumar en restaurantes y bares. Se pusieron en marcha Planes Nacionales de Acción sobre Nutrición y Actividad Física para contrarrestar el aumento de la obesidad.\n",
       "410                                                                                                                                                                                                                                                                                                                                                                                                    Hubo una disminución constante en el porcentaje de estudiantes que afirmaron un alto nivel de satisfacción con la vida, con proporciones más bajas para las niñas en comparación con los niños para cada año de administración de la encuesta (con la excepción de 2006). Una tendencia notable que surgió del análisis de los datos fue la asociación entre un fuerte apoyo social, particularmente el apoyo familiar, y una alta satisfacción con la vida. Este hallazgo subraya el papel fundamental que desempeñan las relaciones positivas y las redes sociales sólidas para contribuir y mejorar el bienestar psicológico de los estudiantes. (Morrison y Peterson, 2016, págs.\n",
       "482                                                                                                                      La oferta insuficiente de programas vocacionales de alta calidad y lugares de estudio de educación terciaria obstaculiza la formación y el crecimiento del capital humano. Estabilizar y simplificar la educación vocacional al enfocarse más en aprendizajes de alta calidad apoyaría la participación. El gobierno necesita encontrar medidas eficientes para aumentar la participación, especialmente entre los niños de familias de bajos ingresos, para reemplazar el subsidio de mantenimiento educativo abolido. Reformas adicionales a la financiación de la educación superior podrían reducir los costos de los contribuyentes y ayudar a financiar una expansión necesaria en el sector. The Implications of School Fundingâ€, CfBT Education Trust Research Paper. Medición de la variación en la efectividad de los maestros en Inglaterra\", documento de trabajo 09/212 del Centro para el Mercado y la Organización Pública, Universidad de Bristol.\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "83                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      En cambio, este capítulo se centra en el papel de la transformación estructural en la reducción de la pobreza, como indica el título de este informe. El número total de personas que viven en la pobreza extrema, según el criterio de la paridad del poder adquisitivo (PPA) de 1,90 dólares al día, se redujo de un máximo de 144 millones en 1999 a 44,6 millones en 2015. En la actualidad, el índice medio de recuento de la pobreza en estas economías es del 11,1%, frente al 45,7% de 1999.\n",
       "1737                                                                                                                                                                                                                                                                                                                              Lerner et al. 1 encontraron resultados similares. (Los autores indican que es posible que no se requieran antidepresivos para todos los empleados con depresión leve, pero cuando se recetan, la medicación debe comenzar lo antes posible. Sin embargo, sigue siendo un hecho que los efectos positivos en el empleo son más bajos que los efectos clínicos (Frank y Koss, 2005), es decir, la mejora clínica no se traduce automática ni completamente en un mejor funcionamiento laboral (medido con escalas de funcionamiento) y un aumento del empleo remunerado con ingresos sustanciales, o en la eliminación de las listas de beneficios por discapacidad. , la mejora de los síntomas no siempre va de la mano con la mejora de la productividad.\n",
       "1242    Un informe conjunto de la OMS y la Organización Mundial de Médicos de Familia (OMS y Wonca, 2008) destaca la importancia de la formación previa al servicio y/o durante el servicio de los trabajadores de atención primaria en salud mental como requisito previo esencial para la integración de la salud mental, y reducir la brecha de tratamiento para la salud mental. La inclusión de capacitación en salud mental para estos profesionales de atención primaria es común en muchos países de la OCDE (OCDE, 2014a), y con el desarrollo de esta nueva especialidad, Japón tiene la valiosa oportunidad de integrar de manera efectiva la capacitación en salud mental para generalistas desde el principio. Específicamente, se puede fortalecer la provisión para los trastornos leves a moderados en el nivel de atención primaria, se ha demostrado que las pautas de prescripción y tratamiento específicas de la atención primaria y las opciones apropiadas de derivación a especialistas son enfoques de tratamiento efectivos para los trastornos leves a moderados.\n",
       "1131                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Los especialistas incluyen pediatras, obstetras/ginecólogos, psiquiatras, especialistas médicos y especialistas quirúrgicos. En estas circunstancias, los médicos de atención primaria tienden a derivar incluso los casos mínimamente justificados a servicios ambulatorios especializados más costosos oa hospitales (Golinowska et al, 2007). Por lo tanto, en lugar de que el tratamiento se concentre en el nivel menos costoso, los costos se desplazan hacia segmentos más costosos.\n",
       "1356           Este capítulo analiza las políticas de preparación, concesión de licencias, evaluación y desarrollo continuo de maestros y directores de Tailandia y las estructuras y organizaciones que las respaldan. Identifica cinco problemas de política que pueden estar impidiendo el desarrollo de una profesión educativa de alta calidad: 1) programas de preparación docente inadecuados, 2) falta de un enfoque estratégico para el desarrollo profesional de los docentes, 3) cargas administrativas que mantienen a los docentes alejados de el aula, 4) ningún marco estratégico para apoyar el desarrollo de líderes escolares, y 5) un enfoque fragmentado para la gestión de datos y el despliegue de docentes que dificulta abordar la escasez de docentes. Esto debe desarrollarse en consulta con los docentes, los líderes escolares y sus asociaciones. La financiación y el despliegue de maestros deberían reflejar mejor las necesidades locales para garantizar que todos los estudiantes reciban enseñanza de maestros altamente calificados y de alta calidad.\n",
       "Name: textos, Length: 728, dtype: object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[\"textos\"]\n",
    "y = df[\"labels\"]\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test_text.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2547d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "import WordTokenizer\n",
    "from WordTokenizer import WordTokenizerTransformer\n",
    "\n",
    "X = df[\"textos\"]\n",
    "y = df[\"labels\"]\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "tokenizer = WordTokenizerTransformer()\n",
    "#df_token = tokenizer.fit_transform(X_train_text)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tokenize', tokenizer),\n",
    "    ('vectorizer', CountVectorizer(ngram_range=(1,1))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train_text, y_train)\n",
    "\n",
    "# Evaluar\n",
    "y_pred = pipeline.predict(X_test_text)\n",
    "\n",
    "cloudpickle.register_pickle_by_value(WordTokenizer)\n",
    "# Serialización del pipeline\n",
    "with open('pipeline.cloudpkl', mode='wb') as file:\n",
    "\n",
    "    cloudpickle.dump(pipeline, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31662b27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX_test\u001b[49m\u001b[38;5;241m.\u001b[39mhead\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824e6c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9752747252747253\n",
      "F1 Score (macro): 0.9721977831629459\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.94      0.96       157\n",
      "           3       0.96      0.99      0.97       255\n",
      "           4       0.99      0.98      0.99       316\n",
      "\n",
      "    accuracy                           0.98       728\n",
      "   macro avg       0.97      0.97      0.97       728\n",
      "weighted avg       0.98      0.98      0.98       728\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      " [[148   7   2]\n",
      " [  2 252   1]\n",
      " [  2   4 310]]\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train_text, y_train)\n",
    "y_pred = pipeline.predict(X_test_text)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nMatriz de confusión:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
